<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》 - Xtar&#39;s blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Xtar" /><meta name="description" content="1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.100.2 with theme even" />


<link rel="canonical" href="https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》" />
<meta property="og:description" content="1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-08-02T18:07:15+08:00" />
<meta property="article:modified_time" content="2022-08-02T18:07:15+08:00" />

<meta itemprop="name" content="论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》">
<meta itemprop="description" content="1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用"><meta itemprop="datePublished" content="2022-08-02T18:07:15+08:00" />
<meta itemprop="dateModified" content="2022-08-02T18:07:15+08:00" />
<meta itemprop="wordCount" content="2482">
<meta itemprop="keywords" content="推理攻击,成员推理,属性推理,联邦学习," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》"/>
<meta name="twitter:description" content="1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Xtar&#39;s blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Xtar&#39;s blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-08-02 </span>
        <div class="post-category">
            <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"> 论文阅读 </a>
            </div>
          <span class="more-meta"> 约 2482 字 </span>
          <span class="more-meta"> 预计阅读 5 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-文章概述">1. 文章概述</a></li>
    <li><a href="#2-背景知识">2. 背景知识</a>
      <ul>
        <li>
          <ul>
            <li><a href="#21-协作学习collaborative-learning">2.1 协作学习（Collaborative learning）</a></li>
            <li><a href="#22-reasoning-about-privacy-in-machine-learning">2.2 Reasoning about Privacy in Machine Learning：</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-推理攻击">3. 推理攻击</a>
      <ul>
        <li>
          <ul>
            <li><a href="#31-threat-model">3.1 Threat model：</a></li>
            <li><a href="#32-overview-of-attacks">3.2 Overview of attacks:</a></li>
            <li><a href="#33-membership-inference">3.3 Membership inference：</a></li>
            <li><a href="#34-passive-property-inference">3.4 Passive property inference:</a></li>
            <li><a href="#34-active-property-inference">3.4 Active property inference</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#4-防御">4. 防御</a>
      <ul>
        <li>
          <ul>
            <li><a href="#41-sharing-fewer-gradients">4.1 Sharing fewer gradients</a></li>
            <li><a href="#42-dimensionality-reduction">4.2 Dimensionality reduction</a></li>
            <li><a href="#43-dropout">4.3 Dropout</a></li>
            <li><a href="#45-participant-level-differential-privacy">4.5 Participant-level differential privacy</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#5-攻击的不足">5. 攻击的不足</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="1-文章概述">1. 文章概述</h1>
<p>本文阐释了 <strong>Collaborative learning</strong> 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用漏洞，敌手可以推断出某个确定数据点的是否存在，即<strong>成员推断攻击</strong>——某个数据点是否参与到了CL训练中。其次，还可以利用漏洞去推测出训练数据集独立于机器学习任务之外的特征——<strong>属性推理攻击</strong> 。</p>
<h1 id="2-背景知识">2. 背景知识</h1>
<h3 id="21-协作学习collaborative-learning">2.1 协作学习（Collaborative learning）</h3>
<p>文章将协作学习分为了 <strong>Collaborative learning with synchronized gradient updates，Federated learning with model averaging</strong> 两种。</p>
<p><strong>(1) Collaborative learning with synchronized gradient updates</strong></p>
<p><img src="https://s2.loli.net/2022/08/02/R7ITgYhSZApCw3Q.png" alt="image-20220729192522352"></p>
<p>在每一轮的迭代过程中，每个参与者从参数服务器中下载全局模型，然后在本地计算梯度更新（基于自己训练数据中的一个batch）并发送给服务器。服务器接收所有参与者的梯度更新，然后对梯度进行聚合，并利用SGD算法对全局模型更新。</p>
<p><strong>(2) Federated learning with model averaging</strong></p>
<p><img src="https://s2.loli.net/2022/08/02/if96Yc5RoNOvltW.png" alt="image-20220729193002397"></p>
<ul>
<li>C：控制每一轮参与者更新的比例，这里设置为 1 ，来简化实验，也是因为我们在分析泄露问题的时候不考虑效率</li>
<li>n ：训练集的 size</li>
<li>$n^k$ ：第k个参与者训练集 size</li>
</ul>
<p>每一轮中，参与者在本地用自己全部的训练数据用 SGD 计算出 $\theta$ , 然后提交服务器(the globally visible updates are based not on batches but on participants&rsquo; entire datasets)
服务器根据收到的结果计算一个加权平均，服务器在测试集上评估生成的联合模型，并在性能停止提高时停止训练。</p>
<h3 id="22-reasoning-about-privacy-in-machine-learning">2.2 Reasoning about Privacy in Machine Learning：</h3>
<p><strong>(1) Inferring class representatives</strong></p>
<p>攻击说明：给定对分类器模型的黑盒访问，推断出每个类的特征，从而可以构造这些类的代表特征。
攻击效果：在特殊情况下，只有在所有类成员都相似的特殊情况下，模型反演的结果与训练数据相似。</p>
<p><strong>(2) Inferring membership in training data</strong></p>
<p>给定一个模型和一个精确的数据点，推断这个数据点是否用于训练模型。</p>
<p><strong>(3) Inferring properties of training data</strong></p>
<p>以往的攻击，都是获取全部数据集所拥有的特征，而本文针对于部分数据集上所拥有的特征。比如在区分性别的数据集上，推断某些图片是否佩戴眼镜，或者某些特定人物是否出现在图片中。</p>
<h1 id="3-推理攻击">3. 推理攻击</h1>
<h3 id="31-threat-model">3.1 Threat model：</h3>
<p>假设有 $k(k \geq 2)$ 个参与者联合训练一个模型，其中有一个参与者是敌手。他的目标是通过分析训练期间联合模型的定期更新来推断有关另一个目标参与者的训练数据的信息。</p>
<p>多参与方（$k \gt  2$）包含既不是敌手也不是目标的诚实参与者。多参与者的情形中，敌手不一定知道参与者的身份，即使被知道了，但由于模型是被汇总的，也无法追踪到某一个具体的参与者。</p>
<p>对于模型平均的机器学习，更新是两步聚合的结果：(1)每个参与者在本地的每个batch上计算出的梯度的聚合; (2)服务器对所有用户的更新的聚合</p>
<p>对于属性推理，敌手需要额外的标注出敌手想要推测的属性以及数据点的主任务属性的训练数据。</p>
<h3 id="32-overview-of-attacks">3.2 Overview of attacks:</h3>
<p><img src="https://s2.loli.net/2022/08/02/COmkift9ZpgrSJB.png" alt="image-20220729193418440"></p>
<p>对于每一次迭代t,敌手下载目前的联合模型，计算梯度更新，并发送给服务器。<br>
敌手保存联合模型参数的快照 $\theta_t$ , 连续的快照之间的差别是 $\Delta \theta_{t}=\theta_{t}-\theta_{t-1}=\sum_{k} \Delta \theta_{t}^{k}$ 即所有参与者的聚合更新，所以 $\Delta \theta_{t}-\Delta \theta_{t}^{adv}$ 表示除了敌手的所有参与者的聚合更新。</p>
<p><strong>(1) Leakage from the embedding layer</strong></p>
<p>嵌入层的矩阵被作为模型参数传递和优化，嵌入层的梯度相对于输入的单词是稀疏的：给定一批文本，嵌入层只使用出现在该批中的单词进行更新。而其他单词的梯度为0。这种差异就会泄露在训练中参与者使用了哪些单词进行训练。</p>
<p><strong>(2)Leakage from the gradients</strong></p>
<ul>
<li>在深度学习模型中，梯度是通过后向传播 loss 计算得到的;</li>
<li>给定层的梯度是使用这层的特征和上层的 error 计算得到的;</li>
<li>对于顺序的全连接层 $h_{l},h_{l+1}(h_{l+1}=W_{l} \cdot h_{l})$ $W_l$ 是权重矩阵，$W_l$ 的误差 $E$ 的梯度由 $\frac{\partial E}{W_{l}}=\frac{\partial E}{h_{l+1}} \cdot h_{l}$ 计算;</li>
<li>$W_l$ 的梯度是来自上层的误差和特征 $h_l$ 的内积。观察到权重的更新可以用于推理特征值，而特征值来自于参与者的私人训练数据集，所以会泄露参与者隐私。</li>
</ul>
<h3 id="33-membership-inference">3.3 Membership inference：</h3>
<p>嵌入层的非0梯度，直接会反映哪些训练数据参与到训练中</p>
<h3 id="34-passive-property-inference">3.4 Passive property inference:</h3>
<p><strong>攻击准备:</strong>   敌手需要额外取得额外的数据，由含有推测属性$D_{prop}^{adv}$和不含推测属性$D_{nonprop}^{adv}$的两部分数据组成，这些数据点需要从目标参与者数据的相同类中取样，但在其他方面可能是不相关的。</p>
<p><strong>攻击直觉：</strong> 敌手可以利用全局模型的快照，根据具有属性的数据生成聚合更新，并根据不具有属性的数据生成更新。这将生成标记的示例，使对手能够训练一个<strong>batch property classifier</strong>，该分类器确定观察到的更新是否基于具有或不具有该属性的数据。</p>
<p><strong>分类器训练算法:</strong>   </p>
<p><img src="https://s2.loli.net/2022/08/02/6POfcpwFk1mjqhz.png" alt="image-20220729193945010"></p>
<p>对于给定模型快照 $\theta_t$ ，基于一批带属性的数据 ($b_{prop}^{adv} \subset D_{prop}^{adv}$) 计算梯度 $g_{prop}$ ，同时基于一批不带属性的数据 ($b_{nonprop}^{adv} \subset D_{nonprop}^{adv}$) 直到收集到足够的带标签的梯度，训练二分类器 $f_{prop}$</p>
<p><strong>推理算法：</strong> </p>
<ul>
<li>在 single-batch 推理中，直接将梯度更新作为输入放入分类器中，得到结果。</li>
<li>扩展到整个数据集，分类器每次输出一个 [0, 1] 间的分数来表示某一 batch 中有此属性的概率，最后使用所有迭代的平均值来决定某目标的整个数据集中是否含有此属性。</li>
</ul>
<h3 id="34-active-property-inference">3.4 Active property inference</h3>
<p>敌手通过利用多任务学习来完成积极的属性推测，对手用连接到最后一层的增广属性分类器扩展其协作训练模型的本地副本。他训练这个模型，使其同时在主任务和识别批属性上都表现良好。</p>
<p>训练数据中每条记录有一个主标签 y 和一个属性标签 p ，模型的联合损失通过以下方式计算：
$L_{\mathrm{mt}}=\alpha \cdot L(x, y ; \theta)+(1-\alpha) \cdot L(x, p ; \theta)$   </p>
<ul>
<li>用这个损失函数训练数据集的话，联合函数会学习数据具有property和不具有property的不同表示</li>
<li>主动攻击和被动攻击的唯一区别：主动攻击进行了额外的本地计算，并将其结果提交至了协同机器学习中</li>
</ul>
<h1 id="4-防御">4. 防御</h1>
<h3 id="41-sharing-fewer-gradients">4.1 Sharing fewer gradients</h3>
<p>实验效果：不好</p>
<p><img src="https://s2.loli.net/2022/08/02/EBr6zdRxk2IipF7.png" alt="image-20220729194724641"></p>
<h3 id="42-dimensionality-reduction">4.2 Dimensionality reduction</h3>
<p>实验效果：虽然能削弱攻击，但对联合训练模型的质量有明显的负面影响</p>
<p><img src="https://s2.loli.net/2022/08/02/4jmFKaG9xcETCiP.png" alt="image-20220729194805044"></p>
<h3 id="43-dropout">4.3 Dropout</h3>
<p>实验效果：随着dropout比例的增大，攻击效果增加，且轻微降低模型准确性</p>
<p><img src="https://s2.loli.net/2022/08/02/uO8yT5xwUCnLbNa.png" alt="image-20220729194848746"></p>
<p>Dropout 在每个协作训练步骤中随机删除特征，从而产生更多信息特征（类似于特征装袋）并增加参与者更新之间的差异。</p>
<h3 id="45-participant-level-differential-privacy">4.5 Participant-level differential privacy</h3>
<p>理论上，参与者层次的差分隐私方法确实可以限制本文中提出的推理攻击，但实际上并没有全部覆盖。因为本文中的参与者太少了（30个）；我们认为，参与者级别的差异隐私仅在涉及至少数千名参与者的环境中提供合理的准确性。</p>
<h1 id="5-攻击的不足">5. 攻击的不足</h1>
<ul>
<li>需要辅助数据，而有时获得辅助数据是不可行的</li>
<li>参与者数量的问题，本文中的模型参与人数较少（2-30人），现实中联邦训练可能涉及成百上千人</li>
<li>不能检测到的属性：有一些特征并不是内部可分的，此时推理攻击就会失败</li>
<li>无法确定推理出的属性的归属</li>
</ul>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Xtar</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2022-08-02
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%8E%A8%E7%90%86%E6%94%BB%E5%87%BB/">推理攻击</a>
          <a href="/tags/%E6%88%90%E5%91%98%E6%8E%A8%E7%90%86/">成员推理</a>
          <a href="/tags/%E5%B1%9E%E6%80%A7%E6%8E%A8%E7%90%86/">属性推理</a>
          <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB5/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">论文阅读5:《GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models》</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB3/">
            <span class="next-text nav-default">论文阅读3:《Inference Attack and Defense on the Distributed Private Fair Machine Learning Framework》</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:xu-hx@foxmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/xhxlalala" class="iconfont icon-github" title="github"></a>
  <a href="https://xtar.netlify.app/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2024<span class="heart"><i class="iconfont icon-heart"></i></span><span>Xtar</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.191509a5c8442abdb6eb5020a332fd59bdd83a7e78a2d2241108df9113504292.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
          displayMath: [['$$','$$'], ['\[\[','\]\]']],
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
