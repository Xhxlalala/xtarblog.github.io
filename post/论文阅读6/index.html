<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》 - Xtar&#39;s blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Xtar" /><meta name="description" content="1 介绍 本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.100.2 with theme even" />


<link rel="canonical" href="http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB6/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.b5a744db6de49a86cadafb3b70f555ab443f83c307a483402259e94726b045ff.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》" />
<meta property="og:description" content="1 介绍 本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB6/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-08-28T20:06:39+08:00" />
<meta property="article:modified_time" content="2022-08-28T20:06:39+08:00" />

<meta itemprop="name" content="论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》">
<meta itemprop="description" content="1 介绍 本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便"><meta itemprop="datePublished" content="2022-08-28T20:06:39+08:00" />
<meta itemprop="dateModified" content="2022-08-28T20:06:39+08:00" />
<meta itemprop="wordCount" content="2445">
<meta itemprop="keywords" content="推理攻击,属性推理,联邦学习," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》"/>
<meta name="twitter:description" content="1 介绍 本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Xtar&#39;s blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Xtar&#39;s blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-08-28 </span>
        <div class="post-category">
            <a href="/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"> 论文阅读 </a>
            </div>
          <span class="more-meta"> 约 2445 字 </span>
          <span class="more-meta"> 预计阅读 5 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#1-介绍">1 介绍</a>
      <ul>
        <li><a href="#threat-model">Threat model</a></li>
        <li><a href="#attack-technique">Attack technique</a></li>
        <li><a href="#methodology">Methodology</a></li>
        <li><a href="#machine-learning-settings">Machine learning settings</a></li>
        <li><a href="#contributions">Contributions</a></li>
      </ul>
    </li>
    <li><a href="#2-预备知识">2 预备知识</a>
      <ul>
        <li>
          <ul>
            <li><a href="#安全多方计算mpc">安全多方计算(MPC)</a></li>
            <li><a href="#多方机器学习">多方机器学习</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-数据模型">3 数据模型</a>
      <ul>
        <li>
          <ul>
            <li><a href="#1-y-perp-a">(1) $Y \perp A$</a></li>
            <li><a href="#2-y-sim-a">(2) $Y \sim A$</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#4-威胁模型及攻击">4 威胁模型及攻击</a>
      <ul>
        <li>
          <ul>
            <li><a href="#shadow-models-and-attack-meta-classifier">Shadow models and attack meta-classifier</a></li>
            <li><a href="#single-party-attack">Single-party attack</a></li>
            <li><a href="#fine-grained-attack">Fine-grained attack</a></li>
            <li><a href="#scope">Scope</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="1-介绍">1 介绍</h1>
<p>本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便于他们可以在池化数据中训练而不必互相共享明文数据。我们发现即使只有对模型的黑盒访问权限，关于一方敏感特征的全局属性也可以被另一方推断出。同时即使这些敏感特征与模型主任务无关我们也可以推断，这可能是因为敏感特征与数据集中其他特征存在联系。</p>
<h2 id="threat-model">Threat model</h2>
<p>我们考虑这样一种设置，即在 <strong>honest party</strong> 和一个 <strong>honest-but-curious party</strong></p>
<p>的联合数据上对模型进行安全训练。Honest-but-curious 敌手考虑现实的设定即恶意方(1)不会改变自己的数据——如果是这样,该模型可能不表现良好,如果检测到,还可能会削弱另一方的信任合作关系,(2)不会改变机器学习代码——双方可能希望观察到代码运行在数据上，以确保其质量和安全。</p>
<p>攻击者感兴趣的是在数据集级别上学习敏感特征的全局属性，即该特征的值如何在另一方的数据集上分布。</p>
<h2 id="attack-technique">Attack technique</h2>
<p>攻击者不需要访问模型的训练过程或者模型参数。攻击者使用 <strong>shadow models</strong> 以及一个 <strong>meta classifier</strong> 。然而，模型中的单个预测不足以提取关于数据集的全局信息。所以，我们依据一系列查询建立了一个攻击向量并且联合使用他们来推理一个数据集的属性。</p>
<h2 id="methodology">Methodology</h2>
<p>为了理解是什么导致了属性的信息泄露，我们考虑了敏感属性 A、其余属性 X 和机器学习模型旨在学习的目标变量 Y 之间的几个相关关系。</p>
<h2 id="machine-learning-settings">Machine learning settings</h2>
<ul>
<li>单方设置，即一个数据集的参与者发布模型的查询接口</li>
<li>模型更新设置，即一方可以推断当模型的一个版本发布后敏感属性的分布是如何变化的</li>
</ul>
<h2 id="contributions">Contributions</h2>
<ul>
<li><strong>问题定义</strong>：当攻击者只能通过黑盒访问模型时，我们研究用于训练机器学习模型的数据集的属性泄露</li>
<li><strong>攻击技术</strong>：我们提出了一种有效的攻击策略，它只需要对模型进行几百次推理查询(黑盒访问)，并依赖于一个简单的攻击体系结构，即使是计算绑定的攻击者也可以使用</li>
<li><strong>攻击设置</strong>：我们表明，对于数据集的所有者来说数据集属性泄漏是一个问题(1)当发布一个训练过的数据模型时(单方设置);(2)当所有者参与多方机器学习，当所有者贡献数据来更新已经训练过的模型时(例如，因为模型加入了其他方或获得了新的数据)</li>
<li><strong>实验结果</strong>：即使敏感属性从训练数据集中删除，且与目标变量的相关性较低，也可以对几种类型的数据集(表格、文本、图)和模型高精度地推断出敏感属性的分布</li>
</ul>
<h1 id="2-预备知识">2 预备知识</h1>
<p>我们假设有一个由变量 X，A，Y 决定的底层数据分布 D，其中 X 表示一系列特征，A 表示一个敏感特征，Y 表示目标变量。我们考虑一个监督设置任务是训练模型 f 使得 f(X, A) 预测 Y 。</p>
<h3 id="安全多方计算mpc">安全多方计算(MPC)</h3>
<p>MPC允许各方在他们的联合数据集上获得计算结果，而无需彼此或与任何人共享明文数据。安全多方计算实现方法包括：同态加密，秘密共享，安全硬件，混淆电路等。</p>
<p>我们使用一个理想的功能抽象MPC：一个可信的第三方实体接受来自各方的输入，在合并的数据上计算所需的函数，并将计算的输出返回给各方。</p>
<h3 id="多方机器学习">多方机器学习</h3>
<p>参与者使用MPC训练f，因为出于隐私考虑或监管他们不愿意分享f。一旦使用MPC对目标模型训练一次，模型就可以以白盒或黑盒方式发送到参与方。MPC保证了参与方只能获得计算的输出，而无法获得更多关于其他参与方的信息。</p>
<ul>
<li>$D_{honest}$ &ndash; 参与方数据集 $P_{honest}$ &ndash; 参与方</li>
<li>$D_{adv}$ &ndash; 受害者被敌手所知的数据集 $P_{adv}$ &ndash; 敌手</li>
</ul>
<p>注意：$D_{honest}$中A的分布敌手是不可知的</p>
<h1 id="3-数据模型">3 数据模型</h1>
<p>我们用 ~ 表示随机变量间相关；用$\perp$ 表示无关；</p>
<h3 id="1-y-perp-a">(1) $Y \perp A$</h3>
<p>根据剩下的特征是否与敏感特征A有关分成两种情况：$(X \perp A, Y \perp A)$与$(X \sim A, Y \perp A)$ </p>
<h3 id="2-y-sim-a">(2) $Y \sim A$</h3>
<p>根据目标变量Y是否与敏感特征A有关分为两种情况：$(X \perp A, Y \sim A)$与$(X \sim A, Y \sim A)$ </p>
<h1 id="4-威胁模型及攻击">4 威胁模型及攻击</h1>
<p>敌方 $p_{adv}$ 的目标是学习有关多方机器学习设置中使用的其余数据集的 population-level 属性(例如，在两方设置中，即为学习另一方数据集的属性)。给定了 f 的访问接口，攻击者想要去推理敏感属性A在诚实方数据集 $D_{honest}$ 中是如何分布的。
<strong>数据泄露建模：</strong> </p>
<ul>
<li>$a_{honest}$ &ndash; $D_{honest}$中所有记录中A的属性值(例如，如果敏感属性是性别，那么 $a_{honest}$ 是 $D_{honest}$中所有记录的性别值的向量)</li>
<li>$p(a_{honest})$ &ndash; 对手试图推断的关于$a_{honest}$的属性或信息(例如，该属性可能与确定数据集 $D_{honest}$ 中是否存在更多女性患者或了解女性患者的确切比例有关)</li>
<li>攻击者除了知道自己的数据集$D_{adv}$以及具有对模型 f 的黑盒访问权限外，还假定具有根据 D 分布的辅助数据集$D_{aux}$ </li>
<li>我们观察到，为了推断训练数据的全局属性，攻击者需要结合 f 做出的多个推断的信息。为此，攻击者测量 f 在 k 个记录序列上的表现，称为$D_{attack}$ (在本实验中我们通过从$D_{aux}$随机抽样来构建)</li>
<li>我们通过将“攻击特征”序列 $F$ 设置为 f 在$D_{attack}$ 上返回的跨类的后验概率向量</li>
</ul>
<h3 id="shadow-models-and-attack-meta-classifier">Shadow models and attack meta-classifier</h3>
<p><img src="https://s2.loli.net/2022/08/28/enup2lD1QdwbEZB.png" alt="image.png"></p>
<p>攻击者训练了 n 个类似 f 的“影子模型”。训练集 $D_{shadow}^{i}$ 中一半包含特定的属性一半不包含，分别记为 $p,\bar{p}$ .每个影子模型 $f_{i}^{shadow}$ 使用与目标模型 f 一样的训练方式在联合数据集 $D_{\text {shadow }}^{i} \bigcup D_{\mathrm{adv}}$ 上进行训练。一旦 $f_{i}^{shadow}$ 训练完，攻击者就使用 $D_{attack}$ 查询它并结合推理结果形成与 $p$ 或 $\bar{p}$ 相关联的特征向量 $F_{i}$ ，具体取决于其训练数据。在训练完所有影子模型后，敌手获得一组特征 $F_{i}$ ，其属性标签为 $p_{i} \in{p, \bar{p}}$. 然后，对手使用任何二元分类算法根据 $\{(F_{i}, p_{i})\}_{i}$ 训练元分类器。</p>
<p><img src="https://s2.loli.net/2022/08/28/tygu4i2soahMcBK.png" alt="image2.png"></p>
<p>当目标模型使用诚实方和攻击方的联合数据训练完后，攻击者使用 $D_{attack}$ 来查询获得目标模型的特征代表$F$, 然后将 $F$ 输入到元分类器并获得对敏感特征的属性预测 $p(a_{honest})$</p>
<h3 id="single-party-attack">Single-party attack</h3>
<p>如果应用在 single-party 情况下，只需要把 $D_{adv}$ 设置为空集即可</p>
<h3 id="fine-grained-attack">Fine-grained attack</h3>
<p>攻击者可以扩展这种二元属性攻击并针对多个属性 $P = \left\{p^{1}, p^{2},&hellip;\right\}$ 进行区分
简单来说就是为每个属性生成影子训练数据集，然后训练元分类器根据攻击向量 F 来预测 P 中的一个属性。</p>
<p>例如，P 可以是一个包含多个女性与其他值比值的集合，然后元分类器试着去推测是 10:90 或 50:50 还是 90:10</p>
<h3 id="scope">Scope</h3>
<p>因为我们的威胁模型与之前那些攻击者推理个人 record-level 的属性，所以我们的模型进行一些修改也可以用于 record-level 的泄露。但是, 与之前的研究类似，我们的攻击无法推断具有大的、甚至无界的域的敏感属性（如：姓名）</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">Xtar</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2022-08-28
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/%E6%8E%A8%E7%90%86%E6%94%BB%E5%87%BB/">推理攻击</a>
          <a href="/tags/%E5%B1%9E%E6%80%A7%E6%8E%A8%E7%90%86/">属性推理</a>
          <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB7/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">论文阅读7:《Label-Only Membership Inference Attacks》</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB5/">
            <span class="next-text nav-default">论文阅读5:《GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models》</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:xu-hx@foxmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://github.com/xhxlalala" class="iconfont icon-github" title="github"></a>
  <a href="http://xtarblog.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2024<span class="heart"><i class="iconfont icon-heart"></i></span><span>Xtar</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.191509a5c8442abdb6eb5020a332fd59bdd83a7e78a2d2241108df9113504292.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
          displayMath: [['$$','$$'], ['\[\[','\]\]']],
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
