<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>成员推理 on Xtar&#39;s blog</title>
    <link>https://xtar.netlify.app/tags/%E6%88%90%E5%91%98%E6%8E%A8%E7%90%86/</link>
    <description>Recent content in 成员推理 on Xtar&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 05 Oct 2022 21:09:31 +0800</lastBuildDate><atom:link href="https://xtar.netlify.app/tags/%E6%88%90%E5%91%98%E6%8E%A8%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>论文阅读14:《TransMIA：Membership Inference Attacks Using Transfer Shadow Training》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB14/</link>
      <pubDate>Wed, 05 Oct 2022 21:09:31 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB14/</guid>
      <description>1 介绍 迁移学习近些年来很受欢迎。在这篇文章中，作者提出了 TransMIA ，使用transfer learning 在源模型上进行成员推理攻击当敌手只能访问迁移模型的参数时。</description>
    </item>
    
    <item>
      <title>论文阅读13:《EncoderMI：Membership Inference against Pre-trainedEncoders in Contrastive Learning》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB13/</link>
      <pubDate>Sun, 25 Sep 2022 21:12:44 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB13/</guid>
      <description>1 介绍 给定一个无标签的图片集或者(图片，文本)对集，对比学习试着去预训练一个图片编码器，作为众多下游任务的特征提取器。给定一个图片编码器，下</description>
    </item>
    
    <item>
      <title>论文阅读12:《Membership Inference Attacks Against Recommender Systems》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB12/</link>
      <pubDate>Sun, 25 Sep 2022 20:32:27 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB12/</guid>
      <description>1 介绍 近年来，推荐系统取得了良好的表现，成为应用最广泛的网络应用之一。然而，推荐系统通常使用高度敏感的用户数据进行训练，从而推荐系统潜在的数</description>
    </item>
    
    <item>
      <title>论文阅读11:《Enhanced Mixup Training：a Defense Method Against Membership InferenceAttack》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB11/</link>
      <pubDate>Sun, 18 Sep 2022 17:07:41 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB11/</guid>
      <description>1 介绍 MIA 通常利用 model-based 或者 metric-based 推理方法来推测一个具体的数据样本是否是目标模型训练集中的成员。现有的防御措施主要有以下两个缺陷： 当前的防御措施主要用</description>
    </item>
    
    <item>
      <title>论文阅读10:《MemGuard：Defending against Black-Box Membership Inference Attacks via Adversarial Examples》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB10/</link>
      <pubDate>Sun, 18 Sep 2022 16:42:36 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB10/</guid>
      <description>1 介绍 成员推理攻击中，攻击者通常训练一个二分类器，输入样本的置信值向量，输出该样本是否为训练集中的成员。成员推理攻击主要利用的是目标模型的过</description>
    </item>
    
    <item>
      <title>论文阅读7:《Label-Only Membership Inference Attacks》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB7/</link>
      <pubDate>Sun, 28 Aug 2022 20:45:42 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB7/</guid>
      <description>1 介绍 以往的成员推理攻击利用的是模型在训练集和测试集上置信值的不同。如果敌手只能获得标签而无法获得具体的置信值，这种攻击就无法得到应用了。本</description>
    </item>
    
    <item>
      <title>论文阅读5:《GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB5/</link>
      <pubDate>Mon, 15 Aug 2022 16:22:14 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB5/</guid>
      <description>1. 文章概述 首次对针对生成模型的成员推理攻击进行了分类 提供了一种有理论根据的攻击校准技术 2. 背景知识 2.1 Generative Model： 生成模型主要有两种，分别是：</description>
    </item>
    
    <item>
      <title>论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/</link>
      <pubDate>Tue, 02 Aug 2022 18:07:15 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/</guid>
      <description>1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用</description>
    </item>
    
    <item>
      <title>论文阅读2:《Membership Inference Attack on Graph Neural Networks》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB2/</link>
      <pubDate>Sun, 17 Jul 2022 21:45:27 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB2/</guid>
      <description>1. 介绍 图神经网络（GNNs） 通常用来生成传统的的深度神经网络或图数据，使用此神经网络可以处理节点分类、链接预测或图分类等任务。本文主要关注训</description>
    </item>
    
    <item>
      <title>论文阅读1:《Membership Inference Attacks Against Machine Learning Models》</title>
      <link>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</link>
      <pubDate>Tue, 05 Jul 2022 11:34:47 +0800</pubDate>
      
      <guid>https://xtar.netlify.app/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</guid>
      <description>1. 介绍 本文主要介绍了一种机器学习模型的推理攻击 &amp;mdash; 成员推理攻击。成员推理攻击即：给定一个数据记录以及对模型的黑盒访问，推断该数据记录是否在模型</description>
    </item>
    
  </channel>
</rss>
