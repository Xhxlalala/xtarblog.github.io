<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>属性推理 on Xtar&#39;s blog</title>
    <link>http://xtarblog.github.io/tags/%E5%B1%9E%E6%80%A7%E6%8E%A8%E7%90%86/</link>
    <description>Recent content in 属性推理 on Xtar&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 04 Sep 2022 21:43:52 +0800</lastBuildDate><atom:link href="http://xtarblog.github.io/tags/%E5%B1%9E%E6%80%A7%E6%8E%A8%E7%90%86/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>论文阅读9:《Property Inference Attacks Against GANs》</title>
      <link>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB9/</link>
      <pubDate>Sun, 04 Sep 2022 21:43:52 +0800</pubDate>
      
      <guid>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB9/</guid>
      <description>1 介绍 本文提出了第一个针对GANs的 属性推理攻击。 具体来说，敌手试着去推测宏观的训练数据集属性，例如用来训练GAN模型的某一属性的样本分布。</description>
    </item>
    
    <item>
      <title>论文阅读8:《 Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations》</title>
      <link>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB8/</link>
      <pubDate>Sun, 04 Sep 2022 21:19:19 +0800</pubDate>
      
      <guid>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB8/</guid>
      <description>1 介绍 本文主要介绍了针对全连接神经网络（FCNNs）的 白盒 环境下的属性推理攻击。具体来说就是推理训练数据集的全局属性，例如数据被生产的环境或</description>
    </item>
    
    <item>
      <title>论文阅读6:《Leakage of Dataset Properties in Multi-Party Machine Learning》</title>
      <link>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB6/</link>
      <pubDate>Sun, 28 Aug 2022 20:06:39 +0800</pubDate>
      
      <guid>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB6/</guid>
      <description>1 介绍 本文主要介绍了针对中心化多参与方机器学习环境下数据集属性的推理攻击，主要是 population-level 的数据集属性推理。安全多方机器学习提供参与方黑盒的访问以便</description>
    </item>
    
    <item>
      <title>论文阅读4:《Exploiting Unintended Feature Leakage in Collaborative Learning》</title>
      <link>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/</link>
      <pubDate>Tue, 02 Aug 2022 18:07:15 +0800</pubDate>
      
      <guid>http://xtarblog.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB4/</guid>
      <description>1. 文章概述 本文阐释了 Collaborative learning 的参数更新过程存在无意地泄露用户训练数据信息的漏洞，并且本文采用了消极和积极的两种攻击方式来利用这个漏洞。首先，利用</description>
    </item>
    
  </channel>
</rss>
